# ğŸ•µï¸â€â™€ï¸ Warm Up: Lady Gaga News Crawler

Your task is to implement a **web crawler** that scrapes Google News results for articles about **Lady Gaga**.

## ğŸŒ Target URL

https://www.google.com/search?q=lady+gaga+in+the+news&tbm=nws&source=univ&tbo=u&sa=X

> âš ï¸ Note: Google may require dynamic rendering â€” consider using Selenium.

---

## ğŸ¯ Goals

For each article on the page, extract:

- `title`
- `description`
- `date`
- `image` (URL)

Store the results as a list of dictionaries or JSON-like structure.

---

## ğŸ§± Folder Structure

Create your code inside:

```bash
assignments/warm-up
```

---

## ğŸ“ Files You May Use

From `examples/simple-crawler/`, you may refer to or reuse:

- `bs4-example.py` â€“ Example using BeautifulSoup
- `selenium-example.py` â€“ Example using Selenium
- `utils/__init__.py` â€“ Useful helpers (e.g., logging, saving data)

---

## ğŸ§ª How to Test Your Crawler

- âœ… Run locally and print extracted results
- âœ… Submit code + results in your PR
- âœ… Use `unittest` or basic function tests if possible
- âŒ Don't hit Google too frequently â€“ use `time.sleep()`

---

## âš ï¸ Important Considerations

- Be gentle: Add delays (`time.sleep(1-2s)`) between interactions
- Handle missing fields (e.g., if image or date is missing)
- Make sure your code is readable and documented

---

## ğŸš€ Submission Instructions

1. Fork this repository
2. Add your solution under `examples/simple-crawler/lady-gaga/`
3. Commit with a clear message (e.g., `feat: add lady gaga crawler`)
4. Open a Pull Request to the original repository

---

## ğŸ§  Bonus

If you'd like, you can:

- Store results in a JSON/CSV file
- Use `headless` browser config with Selenium
- Add screenshots or output samples in your PR

Good luck ğŸ’ƒğŸ¤
